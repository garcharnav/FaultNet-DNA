{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our goal\n",
    "\n",
    "have each .dat file treated as a single row with 2000 data points (will be resized to 50 x 40)\n",
    "put each one of these .dat files into a main dataframe\n",
    "i.e.\n",
    "\n",
    "(a+c+t+g # of dat, 300) x (2000)\n",
    "\n",
    "each single datapoint will be resized to a picture, 50x40, we have 300 of them\n",
    "75 pictures per base\n",
    "\n",
    "make a labels file, 300 x 4 (one hot encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "C\n",
      "G\n",
      "T\n",
      "[[-207.97638578  180.07280633  124.81725379 ... -437.1953854\n",
      "   206.75177055  -98.57610457]\n",
      " [ -67.90753058 -139.75267189 -123.63092518 ...  219.0008219\n",
      "  -126.9087813  -133.07615075]\n",
      " [-200.57816597   74.44650396   23.99452835 ...  113.68002792\n",
      "  -379.79792376   88.68582645]\n",
      " ...\n",
      " [ -27.06981436  117.20208853  271.27015217 ...  291.07867222\n",
      "  -118.45682056   10.35573719]\n",
      " [  30.32838415  248.40394     -62.00122146 ... -193.95503378\n",
      "   217.67315365 -257.97382595]\n",
      " [  10.79077708 -353.25044902  129.41285985 ...   94.67509104\n",
      "   163.16901564 -129.20393461]]\n",
      "73 75 74 75\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]] 73.0 75.0 74.0 75.0\n"
     ]
    }
   ],
   "source": [
    "data = np.zeros((297,2000)) #since _A58 had 1224 points, A_68 also had less substract by 2?\n",
    "i = a_count = c_count = g_count = t_count = 0\n",
    "source_dir = Path('DNA/')\n",
    "\n",
    "for folders in os.listdir(\"DNA/\"):\n",
    "    print(folders)\n",
    "    source_dir = Path('DNA/'+folders)\n",
    "    # absolute_path = os.path.abspath(source_dir)\n",
    "    # print(\"Full path: \" + absolute_path)\n",
    "    # print(\"Directory Path: \" + os.path.dirname(absolute_path))\n",
    "\n",
    "    for raw_data in os.listdir(source_dir):\n",
    "        data_path = Path('DNA/'+folders+'/'+raw_data)\n",
    "        # print(i, raw_data, data_path)\n",
    "\n",
    "        # absolute_path = os.path.abspath(data_path)\n",
    "        # print(\"Full path: \" + absolute_path)\n",
    "        # print(\"Directory Path: \" + os.path.dirname(absolute_path))\n",
    "        # print(np.genfromtxt(data_path, delimiter='\\t'))\n",
    "        # print(np.loadtxt(data_path))\n",
    "        # print(pd.read_csv(data_path,sep=' ',names = ['time', 'current']))\n",
    "\n",
    "        data[i,:] = pd.read_csv(data_path,sep=' ',names = ['time', 'current'])['current'][0:2000]\n",
    "        # print(i, data[i,:])\n",
    "        \n",
    "        i += 1\n",
    "        if folders == 'A':\n",
    "            a_count += 1\n",
    "        elif folders == 'C':\n",
    "            c_count += 1\n",
    "        elif folders == 'G':\n",
    "            g_count += 1\n",
    "        else:\n",
    "            t_count += 1\n",
    "\n",
    "\n",
    "print(data)\n",
    "print(a_count, c_count, g_count, t_count)\n",
    "\n",
    "labels = np.zeros((297,4))\n",
    "for j in range(len(labels)):\n",
    "    if j < a_count:\n",
    "        labels[j,0] = 1\n",
    "    elif a_count <= j < (a_count + c_count):\n",
    "        labels[j,1] = 1\n",
    "    elif (a_count + c_count) <= j < (a_count + c_count + g_count):\n",
    "        labels[j,2] = 1\n",
    "    elif j >= (a_count + c_count + g_count):\n",
    "        labels[j,3] = 1\n",
    "\n",
    "print(labels, np.sum(labels[:,0]), np.sum(labels[:,1]), np.sum(labels[:,2]), np.sum(labels[:,3]))\n",
    "\n",
    "labels2 = np.zeros((297))\n",
    "for j in range(len(labels)):\n",
    "    if j < a_count:\n",
    "        labels2[j] = 0\n",
    "    elif a_count <= j < (a_count + c_count):\n",
    "        labels2[j] = 1\n",
    "    elif (a_count + c_count) <= j < (a_count + c_count + g_count):\n",
    "        labels2[j] = 2\n",
    "    elif j >= (a_count + c_count + g_count):\n",
    "        labels2[j] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296, 1600) (296,)\n"
     ]
    }
   ],
   "source": [
    "# x=data[:,0:1600]\n",
    "x=data[0:-1,200:-200]\n",
    "labels=labels[0:-1,:]\n",
    "labels2=labels2[0:-1]\n",
    "\n",
    "\n",
    "print(x.shape, labels2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(data,no_elements):\n",
    "    X=np.zeros((data.shape[0],data.shape[1]))\n",
    "    for i in range(data.shape[1]-no_elements+1):\n",
    "        X[:,i]=np.mean(data[:,i:i+no_elements],axis=1)\n",
    "    return X.astype(np.float16)\n",
    "def median(data,no_elements):\n",
    "    X=np.zeros((data.shape[0],data.shape[1]))\n",
    "    for i in range(data.shape[1]-no_elements+1):\n",
    "        X[:,i]=np.median(data[:,i:i+no_elements],axis=1)\n",
    "    return X.astype(np.float16)\n",
    "def sig_image(data,size1,size2):\n",
    "    X=np.zeros((data.shape[0],size1,size2))\n",
    "    for i in range(data.shape[0]):\n",
    "        X[i]=(data[i,:].reshape(size1,size2))\n",
    "    return X.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_mean=(mean(x,10)).astype(np.float16)\n",
    "x_m=sig_image(channel_mean,40,40)\n",
    "channel_median=(median(x,10)).astype(np.float16)\n",
    "x_md=sig_image(x,40,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_n=sig_image(x,40,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296, 40, 40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296, 40, 40)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.stack((x_n,x_m,x_md),axis=1).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296, 3, 40, 40)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(236, 3, 40, 40) (60, 3, 40, 40) (236,) (60,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainx, testx, trainlabel, testlabel = train_test_split(X, labels2, test_size=0.2, random_state=20)\n",
    "\n",
    "print(trainx.shape, testx.shape, trainlabel.shape, testlabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_train, sig_test = trainx,testx\n",
    "lab_train, lab_test = trainlabel,testlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_train = torch.from_numpy(sig_train)\n",
    "sig_test = torch.from_numpy(sig_test)\n",
    "lab_train= torch.from_numpy(lab_train)\n",
    "lab_test = torch.from_numpy(lab_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.2506e+02,  6.1906e+01, -2.1800e+02,  ...,  1.0281e+02,\n",
      "           1.3789e+01, -4.3719e+01],\n",
      "         [ 9.1500e+01, -1.6612e+02,  1.0775e+02,  ...,  2.2500e+01,\n",
      "           5.0859e+00,  1.2256e+02],\n",
      "         [-2.5925e+02,  1.4375e+02, -4.2891e+00,  ..., -6.3531e+01,\n",
      "           1.0806e+02,  9.6438e+01],\n",
      "         ...,\n",
      "         [-2.5250e+02,  1.0119e+02, -8.9250e+01,  ...,  2.6828e+01,\n",
      "          -9.1938e+01, -2.0703e+01],\n",
      "         [ 5.9141e+00,  4.7000e+01,  3.3594e+01,  ..., -5.9469e+01,\n",
      "           2.4438e+02, -1.1231e+02],\n",
      "         [ 1.1062e+02,  3.9031e+01, -2.0275e+02,  ...,  1.5350e+02,\n",
      "          -5.7438e+01,  2.6312e+01]],\n",
      "\n",
      "        [[-1.2727e+01,  5.9375e+00, -6.5117e+00,  ...,  1.2129e+00,\n",
      "           4.0991e-01, -1.1547e+01],\n",
      "         [-7.7188e+00,  1.4906e+01,  2.3547e+01,  ...,  2.2688e+01,\n",
      "           8.7969e+00, -3.7871e+00],\n",
      "         [-3.4531e+01, -7.4492e+00, -1.4023e+00,  ...,  4.9844e+01,\n",
      "           5.3719e+01,  5.1438e+01],\n",
      "         ...,\n",
      "         [-9.6172e+00,  1.5398e+01,  4.2125e+01,  ..., -2.3531e+01,\n",
      "          -9.6406e+00,  7.2656e+00],\n",
      "         [ 3.5020e+00,  1.4612e-01, -1.3625e+01,  ...,  3.7969e+01,\n",
      "           4.6719e+01,  8.1953e+00],\n",
      "         [ 2.4938e+01, -3.2910e+00, -5.8281e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.2506e+02,  6.1906e+01, -2.1800e+02,  ...,  1.0281e+02,\n",
      "           1.3789e+01, -4.3719e+01],\n",
      "         [ 9.1500e+01, -1.6612e+02,  1.0775e+02,  ...,  2.2500e+01,\n",
      "           5.0859e+00,  1.2256e+02],\n",
      "         [-2.5925e+02,  1.4375e+02, -4.2891e+00,  ..., -6.3531e+01,\n",
      "           1.0806e+02,  9.6438e+01],\n",
      "         ...,\n",
      "         [-2.5250e+02,  1.0119e+02, -8.9250e+01,  ...,  2.6828e+01,\n",
      "          -9.1938e+01, -2.0703e+01],\n",
      "         [ 5.9141e+00,  4.7000e+01,  3.3594e+01,  ..., -5.9469e+01,\n",
      "           2.4438e+02, -1.1231e+02],\n",
      "         [ 1.1062e+02,  3.9031e+01, -2.0275e+02,  ...,  1.5350e+02,\n",
      "          -5.7438e+01,  2.6312e+01]]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data_utils\n",
    "batch_size = 2\n",
    "train_tensor = data_utils.TensorDataset(sig_train, lab_train) \n",
    "train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)\n",
    "print(sig_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "test_tensor = data_utils.TensorDataset(sig_test, lab_test) \n",
    "test_loader = data_utils.DataLoader(dataset = test_tensor, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([236, 3, 40, 40])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 3, 40, 40])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3,stride=1,padding = 1)\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=3,stride=1)\n",
    "        self.conv2 = nn.Conv2d(32,64, kernel_size=3,stride =1)\n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=3,stride=1)\n",
    "        self.fc1= nn.Linear(92416,256)\n",
    "        self.fc2 = nn.Linear(46208,23104)\n",
    "        self.fc3 = nn.Linear(23104,11552)\n",
    "        self.fc4 = nn.Linear(11552, 256)\n",
    "        # self.dp1 = nn.Dropout(p=0.2)\n",
    "        self.fc5 = nn.Linear(256,4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        # print(in_size)\n",
    "        x = F.relu((self.conv1(x)))\n",
    "        # print(\"step1\", x)\n",
    "        x = F.relu((self.conv2(x)))\n",
    "        # print(\"step2\", x)\n",
    "        # print('step2',x.shape)\n",
    "        x = x.view(in_size,-1)\n",
    "        # print(\"step3\", x.shape, x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # print(\"step4\", x)\n",
    "        # x = self.dp1(x)\n",
    "        # print(\"step5\", x)\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = F.relu(self.fc3(x))\n",
    "        #x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "\n",
    "        return x #F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN().double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -5.5793,   1.1095,  -6.5323,   1.5765],\n",
      "        [-11.6472,  -0.8273,  -7.8066,  -1.6623]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [1/118], Loss: 4.1473, Train Accuracy: 0.00%\n",
      "tensor([[-9.1762e+00, -2.5382e+00, -4.7761e+00, -9.9824e+00],\n",
      "        [-7.7912e+00, -1.4705e+00, -7.0357e+00,  6.8461e-03]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [2/118], Loss: 5.1728, Train Accuracy: 0.00%\n",
      "tensor([[-3.4990, -0.7954, -7.6448, -9.6389],\n",
      "        [-3.4023, -0.8468,  1.4224, -6.8181]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [3/118], Loss: 3.5106, Train Accuracy: 50.00%\n",
      "tensor([[-3.3707, -5.1713, -2.1183, -1.6513],\n",
      "        [-4.9483, -5.5316, -3.0912, -7.1522]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [4/118], Loss: 1.8731, Train Accuracy: 0.00%\n",
      "tensor([[-6.0403, -4.5912, -5.7313, -5.8944],\n",
      "        [-2.4516, -0.6719,  4.0593, -5.0477]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [5/118], Loss: 1.0309, Train Accuracy: 50.00%\n",
      "tensor([[    nan,     nan,     nan,     nan],\n",
      "        [-2.2367, -5.5879,  1.3452, -7.0032]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [6/118], Loss: nan, Train Accuracy: 100.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [7/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [8/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [9/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [10/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [11/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [12/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [13/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [14/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [15/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [16/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [17/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [18/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [19/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [20/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [21/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [22/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [23/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [24/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [25/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [26/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [27/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [28/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [29/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [30/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [31/118], Loss: nan, Train Accuracy: 100.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [32/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [33/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [34/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [35/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [36/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [37/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [38/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [39/118], Loss: nan, Train Accuracy: 100.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [40/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [41/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [42/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [43/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [44/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [45/118], Loss: nan, Train Accuracy: 100.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [46/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [47/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [48/118], Loss: nan, Train Accuracy: 100.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [49/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [50/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [51/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [52/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [53/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [54/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [55/118], Loss: nan, Train Accuracy: 100.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [56/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [57/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [58/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [59/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [60/118], Loss: nan, Train Accuracy: 100.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [61/118], Loss: nan, Train Accuracy: 0.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [62/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [63/118], Loss: nan, Train Accuracy: 50.00%\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/100], Step [64/118], Loss: nan, Train Accuracy: 0.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\17819\\Documents\\Courses\\24787 ML AI for Engineers\\Projects\\FaultNet-DNA-main\\FaultNet.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/17819/Documents/Courses/24787%20ML%20AI%20for%20Engineers/Projects/FaultNet-DNA-main/FaultNet.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m acc_list \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/17819/Documents/Courses/24787%20ML%20AI%20for%20Engineers/Projects/FaultNet-DNA-main/FaultNet.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/17819/Documents/Courses/24787%20ML%20AI%20for%20Engineers/Projects/FaultNet-DNA-main/FaultNet.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, (signals, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/17819/Documents/Courses/24787%20ML%20AI%20for%20Engineers/Projects/FaultNet-DNA-main/FaultNet.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/17819/Documents/Courses/24787%20ML%20AI%20for%20Engineers/Projects/FaultNet-DNA-main/FaultNet.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39m# Run the forward pass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\17819\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\17819\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\17819\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\17819\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[1;32mc:\\Users\\17819\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:143\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    140\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\17819\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:143\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    140\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\17819\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:120\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 120\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[0;32m    122\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    123\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\17819\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:163\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    161\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    162\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[1;32m--> 163\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (signals, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # Run the forward pass\n",
    "        signals=signals\n",
    "        labels=labels\n",
    "        outputs = cnn(signals.double())\n",
    "        print(outputs)\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        # print(labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels.long()).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "        if (epoch+1) % 5 == 0 or epoch==0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Train Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step = len(test_loader)\n",
    "print(total_step)\n",
    "loss_list_test = []\n",
    "acc_list_test = []\n",
    "with torch.no_grad():\n",
    "    for i, (signals, labels) in enumerate(test_loader):\n",
    "        # Run the forward pass\n",
    "        signals=signals\n",
    "        labels=labels\n",
    "        outputs = cnn(signals.double())\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss_list_test.append(loss.item())\n",
    "        if epoch%10 ==0:\n",
    "            print(loss)\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels.long()).sum().item()\n",
    "        acc_list_test.append(correct / total)\n",
    "        if (epoch) % 1 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you need to save\n",
    "torch.save(cnn,'cnnTC3_fold3_45.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c660cea963f28d21bb3fc0b73504aa5722e9ac72bcf9d7cf78db2ee345c392b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
