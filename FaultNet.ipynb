{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our goal\n",
    "\n",
    "have each .dat file treated as a single row with 2000 data points (will be resized to 50 x 40)\n",
    "put each one of these .dat files into a main dataframe\n",
    "i.e.\n",
    "\n",
    "(a+c+t+g # of dat, 300) x (2000)\n",
    "\n",
    "each single datapoint will be resized to a picture, 50x40, we have 300 of them\n",
    "75 pictures per base\n",
    "\n",
    "make a labels file, 300 x 4 (one hot encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "C\n",
      "G\n",
      "T\n",
      "[[-207.97638578  180.07280633  124.81725379 ... -437.1953854\n",
      "   206.75177055  -98.57610457]\n",
      " [ -67.90753058 -139.75267189 -123.63092518 ...  219.0008219\n",
      "  -126.9087813  -133.07615075]\n",
      " [-200.57816597   74.44650396   23.99452835 ...  113.68002792\n",
      "  -379.79792376   88.68582645]\n",
      " ...\n",
      " [ -27.06981436  117.20208853  271.27015217 ...  291.07867222\n",
      "  -118.45682056   10.35573719]\n",
      " [  30.32838415  248.40394     -62.00122146 ... -193.95503378\n",
      "   217.67315365 -257.97382595]\n",
      " [  10.79077708 -353.25044902  129.41285985 ...   94.67509104\n",
      "   163.16901564 -129.20393461]]\n",
      "73 75 74 75\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]] 73.0 75.0 74.0 75.0\n"
     ]
    }
   ],
   "source": [
    "data = np.zeros((297,2000)) #since _A58 had 1224 points, A_68 also had less substract by 2?\n",
    "i = a_count = c_count = g_count = t_count = 0\n",
    "source_dir = Path('DNA/')\n",
    "\n",
    "for folders in os.listdir(\"DNA/\"):\n",
    "    print(folders)\n",
    "    source_dir = Path('DNA/'+folders)\n",
    "    # absolute_path = os.path.abspath(source_dir)\n",
    "    # print(\"Full path: \" + absolute_path)\n",
    "    # print(\"Directory Path: \" + os.path.dirname(absolute_path))\n",
    "\n",
    "    for raw_data in os.listdir(source_dir):\n",
    "        data_path = Path('DNA/'+folders+'/'+raw_data)\n",
    "        # print(i, raw_data, data_path)\n",
    "\n",
    "        # absolute_path = os.path.abspath(data_path)\n",
    "        # print(\"Full path: \" + absolute_path)\n",
    "        # print(\"Directory Path: \" + os.path.dirname(absolute_path))\n",
    "        # print(np.genfromtxt(data_path, delimiter='\\t'))\n",
    "        # print(np.loadtxt(data_path))\n",
    "        # print(pd.read_csv(data_path,sep=' ',names = ['time', 'current']))\n",
    "\n",
    "        data[i,:] = pd.read_csv(data_path,sep=' ',names = ['time', 'current'])['current'][0:2000]\n",
    "        # print(i, data[i,:])\n",
    "        \n",
    "        i += 1\n",
    "        if folders == 'A':\n",
    "            a_count += 1\n",
    "        elif folders == 'C':\n",
    "            c_count += 1\n",
    "        elif folders == 'G':\n",
    "            g_count += 1\n",
    "        else:\n",
    "            t_count += 1\n",
    "\n",
    "\n",
    "print(data)\n",
    "print(a_count, c_count, g_count, t_count)\n",
    "\n",
    "labels = np.zeros((297,4))\n",
    "for j in range(len(labels)):\n",
    "    if j < a_count:\n",
    "        labels[j,0] = 1\n",
    "    elif a_count <= j < (a_count + c_count):\n",
    "        labels[j,1] = 1\n",
    "    elif (a_count + c_count) <= j < (a_count + c_count + g_count):\n",
    "        labels[j,2] = 1\n",
    "    elif j >= (a_count + c_count + g_count):\n",
    "        labels[j,3] = 1\n",
    "\n",
    "print(labels, np.sum(labels[:,0]), np.sum(labels[:,1]), np.sum(labels[:,2]), np.sum(labels[:,3]))\n",
    "\n",
    "labels2 = np.zeros((297))\n",
    "for j in range(len(labels)):\n",
    "    if j < a_count:\n",
    "        labels2[j] = 0\n",
    "    elif a_count <= j < (a_count + c_count):\n",
    "        labels2[j] = 1\n",
    "    elif (a_count + c_count) <= j < (a_count + c_count + g_count):\n",
    "        labels2[j] = 2\n",
    "    elif j >= (a_count + c_count + g_count):\n",
    "        labels2[j] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296, 1600) (296,)\n"
     ]
    }
   ],
   "source": [
    "# x=data[:,0:1600]\n",
    "x=data[0:-1,200:-200]\n",
    "labels=labels[0:-1,:]\n",
    "labels2=labels2[0:-1]\n",
    "\n",
    "\n",
    "print(x.shape, labels2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(data,no_elements):\n",
    "    X=np.zeros((data.shape[0],data.shape[1]))\n",
    "    for i in range(data.shape[1]-no_elements+1):\n",
    "        X[:,i]=np.mean(data[:,i:i+no_elements],axis=1)\n",
    "    return X.astype(np.float16)\n",
    "def median(data,no_elements):\n",
    "    X=np.zeros((data.shape[0],data.shape[1]))\n",
    "    for i in range(data.shape[1]-no_elements+1):\n",
    "        X[:,i]=np.median(data[:,i:i+no_elements],axis=1)\n",
    "    return X.astype(np.float16)\n",
    "def sig_image(data,size1,size2):\n",
    "    X=np.zeros((data.shape[0],size1,size2))\n",
    "    for i in range(data.shape[0]):\n",
    "        X[i]=(data[i,:].reshape(size1,size2))\n",
    "    return X.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_mean=(mean(x,10)).astype(np.float16)\n",
    "x_m=sig_image(channel_mean,40,40)\n",
    "channel_median=(median(x,10)).astype(np.float16)\n",
    "x_md=sig_image(x,40,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_n=sig_image(x,40,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296, 40, 40)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296, 40, 40)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.stack((x_n,x_m,x_md),axis=1).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296, 3, 40, 40)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(236, 3, 40, 40) (60, 3, 40, 40) (236,) (60,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainx, testx, trainlabel, testlabel = train_test_split(X, labels2, test_size=0.2, random_state=20)\n",
    "\n",
    "# print(trainx.shape, testx.shape, trainlabel.shape, testlabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_train, sig_test = trainx,testx\n",
    "lab_train, lab_test = trainlabel,testlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_train = torch.from_numpy(sig_train)\n",
    "sig_test = torch.from_numpy(sig_test)\n",
    "lab_train= torch.from_numpy(lab_train)\n",
    "lab_test = torch.from_numpy(lab_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "batch_size = 118\n",
    "train_tensor = data_utils.TensorDataset(sig_train, lab_train) \n",
    "train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60\n",
    "test_tensor = data_utils.TensorDataset(sig_test, lab_test) \n",
    "test_loader = data_utils.DataLoader(dataset = test_tensor, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([236, 3, 40, 40])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 3, 40, 40])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=4,stride=1,padding = 1)\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=4,stride=2)\n",
    "        self.conv2 = nn.Conv2d(32,64, kernel_size=4,stride =1)\n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=4,stride=2)\n",
    "        self.fc1= nn.Linear(2304,256)\n",
    "        self.dp1 = nn.Dropout(p=0.2)\n",
    "        self.fc2 = nn.Linear(256,4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = F.relu(self.mp1(self.conv1(x)))\n",
    "        x = F.relu(self.mp2(self.conv2(x)))\n",
    "        x = x.view(in_size,-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dp1(x)\n",
    "        x = self.fc2(x)     \n",
    "        print('here')   \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN().double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([118, 4])\n",
      "Epoch [1/100], Step [1/2], Loss: nan, Train Accuracy: 25.42%\n",
      "torch.Size([118, 4])\n",
      "Epoch [1/100], Step [2/2], Loss: nan, Train Accuracy: 22.03%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [5/100], Step [1/2], Loss: nan, Train Accuracy: 25.42%\n",
      "torch.Size([118, 4])\n",
      "Epoch [5/100], Step [2/2], Loss: nan, Train Accuracy: 22.03%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [10/100], Step [1/2], Loss: nan, Train Accuracy: 27.12%\n",
      "torch.Size([118, 4])\n",
      "Epoch [10/100], Step [2/2], Loss: nan, Train Accuracy: 20.34%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [15/100], Step [1/2], Loss: nan, Train Accuracy: 22.03%\n",
      "torch.Size([118, 4])\n",
      "Epoch [15/100], Step [2/2], Loss: nan, Train Accuracy: 25.42%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [20/100], Step [1/2], Loss: nan, Train Accuracy: 27.12%\n",
      "torch.Size([118, 4])\n",
      "Epoch [20/100], Step [2/2], Loss: nan, Train Accuracy: 20.34%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [25/100], Step [1/2], Loss: nan, Train Accuracy: 24.58%\n",
      "torch.Size([118, 4])\n",
      "Epoch [25/100], Step [2/2], Loss: nan, Train Accuracy: 22.88%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [30/100], Step [1/2], Loss: nan, Train Accuracy: 26.27%\n",
      "torch.Size([118, 4])\n",
      "Epoch [30/100], Step [2/2], Loss: nan, Train Accuracy: 21.19%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [35/100], Step [1/2], Loss: nan, Train Accuracy: 23.73%\n",
      "torch.Size([118, 4])\n",
      "Epoch [35/100], Step [2/2], Loss: nan, Train Accuracy: 23.73%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [40/100], Step [1/2], Loss: nan, Train Accuracy: 22.03%\n",
      "torch.Size([118, 4])\n",
      "Epoch [40/100], Step [2/2], Loss: nan, Train Accuracy: 25.42%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [45/100], Step [1/2], Loss: nan, Train Accuracy: 27.97%\n",
      "torch.Size([118, 4])\n",
      "Epoch [45/100], Step [2/2], Loss: nan, Train Accuracy: 19.49%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [50/100], Step [1/2], Loss: nan, Train Accuracy: 19.49%\n",
      "torch.Size([118, 4])\n",
      "Epoch [50/100], Step [2/2], Loss: nan, Train Accuracy: 27.97%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [55/100], Step [1/2], Loss: nan, Train Accuracy: 22.03%\n",
      "torch.Size([118, 4])\n",
      "Epoch [55/100], Step [2/2], Loss: nan, Train Accuracy: 25.42%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [60/100], Step [1/2], Loss: nan, Train Accuracy: 21.19%\n",
      "torch.Size([118, 4])\n",
      "Epoch [60/100], Step [2/2], Loss: nan, Train Accuracy: 26.27%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [65/100], Step [1/2], Loss: nan, Train Accuracy: 26.27%\n",
      "torch.Size([118, 4])\n",
      "Epoch [65/100], Step [2/2], Loss: nan, Train Accuracy: 21.19%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [70/100], Step [1/2], Loss: nan, Train Accuracy: 25.42%\n",
      "torch.Size([118, 4])\n",
      "Epoch [70/100], Step [2/2], Loss: nan, Train Accuracy: 22.03%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [75/100], Step [1/2], Loss: nan, Train Accuracy: 19.49%\n",
      "torch.Size([118, 4])\n",
      "Epoch [75/100], Step [2/2], Loss: nan, Train Accuracy: 27.97%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [80/100], Step [1/2], Loss: nan, Train Accuracy: 20.34%\n",
      "torch.Size([118, 4])\n",
      "Epoch [80/100], Step [2/2], Loss: nan, Train Accuracy: 27.12%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [85/100], Step [1/2], Loss: nan, Train Accuracy: 22.88%\n",
      "torch.Size([118, 4])\n",
      "Epoch [85/100], Step [2/2], Loss: nan, Train Accuracy: 24.58%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [90/100], Step [1/2], Loss: nan, Train Accuracy: 24.58%\n",
      "torch.Size([118, 4])\n",
      "Epoch [90/100], Step [2/2], Loss: nan, Train Accuracy: 22.88%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [95/100], Step [1/2], Loss: nan, Train Accuracy: 21.19%\n",
      "torch.Size([118, 4])\n",
      "Epoch [95/100], Step [2/2], Loss: nan, Train Accuracy: 26.27%\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "torch.Size([118, 4])\n",
      "Epoch [100/100], Step [1/2], Loss: nan, Train Accuracy: 20.34%\n",
      "torch.Size([118, 4])\n",
      "Epoch [100/100], Step [2/2], Loss: nan, Train Accuracy: 27.12%\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (signals, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # Run the forward pass\n",
    "        signals=signals\n",
    "        labels=labels\n",
    "        outputs = cnn(signals.double())\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        \n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels.long()).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "        if (epoch+1) % 5 == 0 or epoch==0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Train Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([60, 4])\n",
      "Epoch [100/100], Step [1/1], Loss: nan, Accuracy: 28.33%\n"
     ]
    }
   ],
   "source": [
    "total_step = len(test_loader)\n",
    "print(total_step)\n",
    "loss_list_test = []\n",
    "acc_list_test = []\n",
    "with torch.no_grad():\n",
    "    for i, (signals, labels) in enumerate(test_loader):\n",
    "        # Run the forward pass\n",
    "        signals=signals\n",
    "        labels=labels\n",
    "        outputs = cnn(signals.double())\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss_list_test.append(loss.item())\n",
    "        if epoch%10 ==0:\n",
    "            print(loss)\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels.long()).sum().item()\n",
    "        acc_list_test.append(correct / total)\n",
    "        if (epoch) % 1 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# if you need to save\n",
    "torch.save(cnn,'cnnTC3_fold3_45.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c660cea963f28d21bb3fc0b73504aa5722e9ac72bcf9d7cf78db2ee345c392b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
